{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOc1oE0sz1oMTfTPsW+NJ0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casual-lab/MLC-Learn/blob/main/chapter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw9sOre6hc6q",
        "outputId": "1f140b79-033d-463e-faf1-ad014bc1b8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://mlc.ai/wheels\n",
            "Requirement already satisfied: mlc-ai-nightly in /usr/local/lib/python3.10/dist-packages (0.15.dev570)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (3.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (1.13.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install mlc-ai-nightly -f https://mlc.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "第二章的主要内容是熟悉基本工具使用（TVM）。\n",
        "\n",
        "总结来说，TVM提供了一个“算法”与“具体部署环境”之间的额外抽象层。使得算法和部署环境解耦。\n",
        "\n"
      ],
      "metadata": {
        "id": "L58aMiPEKs2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import tir as T"
      ],
      "metadata": {
        "id": "GwsJLK0pjI7o"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init data\n",
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(16, 0, -1).reshape(4, 4)"
      ],
      "metadata": {
        "id": "kN9Dk7rROpJC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "id": "sRyo7KcjO5c5",
        "outputId": "748da00b-2da7-41f6-8a7e-ea7989583ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# low-level numpy version\n",
        "def lnumpy_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      c[i, j] = a[i, j] + b[i, j]\n",
        "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
        "lnumpy_add(a, b, c_lnumpy)\n",
        "c_lnumpy"
      ],
      "metadata": {
        "id": "Tpv4vCczPOK5",
        "outputId": "ed3f3002-5cf7-4137-acd9-d58b147b90e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorIR version\n",
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer((4, 4), \"int64\"),\n",
        "          B: T.Buffer((4, 4), \"int64\"),\n",
        "          C: T.Buffer((4, 4), \"int64\")):\n",
        "    T.func_attr({\"global_symbol\": \"add\"})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "REs70iiJR16Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5.1.2. 练习 1：广播加法¶\n"
      ],
      "metadata": {
        "id": "-8r1QmjCUO4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init data\n",
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(4, 0, -1).reshape(4)\n",
        "a,b"
      ],
      "metadata": {
        "id": "QjsnerY5SBBZ",
        "outputId": "d4fd75d4-5dee-4365-b7db-0d099327a603",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15]]),\n",
              " array([4, 3, 2, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "id": "1Cu2AVkhSE7R",
        "outputId": "59aec5a8-220e-4213-fe2f-e779dda85c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  4,  4,  4],\n",
              "       [ 8,  8,  8,  8],\n",
              "       [12, 12, 12, 12],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer((4, 4), \"int64\"),\n",
        "          B: T.Buffer((4,), \"int64\"),\n",
        "          C: T.Buffer((4, 4), \"int64\")):\n",
        "    T.func_attr({\"global_symbol\": \"add\"})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vj]\n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "TsOYeTmjSIk5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5.1.3. 练习 2：二维卷积¶\n"
      ],
      "metadata": {
        "id": "iJqWGtR9UzSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
        "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
        "data = np.arange(N*CI*H*W).reshape(N, CI, H, W)\n",
        "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K)"
      ],
      "metadata": {
        "id": "iRwjBGOjU3Wr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch version\n",
        "import torch\n",
        "\n",
        "data_torch = torch.Tensor(data)\n",
        "weight_torch = torch.Tensor(weight)\n",
        "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
        "conv_torch = conv_torch.numpy().astype(np.int64)\n",
        "conv_torch"
      ],
      "metadata": {
        "id": "cvnIiJmHVR-h",
        "outputId": "d474af28-c731-422b-d86f-b5a9024d7b74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 474,  510,  546,  582,  618,  654],\n",
              "         [ 762,  798,  834,  870,  906,  942],\n",
              "         [1050, 1086, 1122, 1158, 1194, 1230],\n",
              "         [1338, 1374, 1410, 1446, 1482, 1518],\n",
              "         [1626, 1662, 1698, 1734, 1770, 1806],\n",
              "         [1914, 1950, 1986, 2022, 2058, 2094]],\n",
              "\n",
              "        [[1203, 1320, 1437, 1554, 1671, 1788],\n",
              "         [2139, 2256, 2373, 2490, 2607, 2724],\n",
              "         [3075, 3192, 3309, 3426, 3543, 3660],\n",
              "         [4011, 4128, 4245, 4362, 4479, 4596],\n",
              "         [4947, 5064, 5181, 5298, 5415, 5532],\n",
              "         [5883, 6000, 6117, 6234, 6351, 6468]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyConv:\n",
        "  @T.prim_func\n",
        "  def conv(D: T.buffer((N, CI, H, W), \"int64\"),\n",
        "           W: T.buffer((CO, CI, K, K), \"int64\"),\n",
        "           O: T.buffer((N, CO, OUT_H, OUT_W), \"int64\")):\n",
        "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
        "    for n, co, h, w in T.grid(N, CO, OUT_H, OUT_W):\n",
        "        with T.block(\"O\"):\n",
        "            vn = T.axis.spatial(N, n)\n",
        "            vco = T.axis.spatial(CO, co)\n",
        "            vh = T.axis.spatial(OUT_H, h)\n",
        "            vw = T.axis.spatial(OUT_W, w)\n",
        "            with T.init():\n",
        "                O[vn, vco, vh, vw] = 0\n",
        "            for ci, kh, kw in T.grid(CI, K, K):\n",
        "                with T.block(\"C\"):\n",
        "                    vcci = T.axis.spatial(CI, ci)\n",
        "                    vkh = T.axis.reduce(K, kh)\n",
        "                    vkw = T.axis.reduce(K, kw)\n",
        "                    O[vn, vco, vh, vw] = O[vn, vco, vh, vw] + \\\n",
        "                        D[vn, vcci, vh + vkh, vw + vkw] * W[vco, vcci, vkh, vkw]\n",
        "\n",
        "\n",
        "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
        "data_tvm = tvm.nd.array(data)\n",
        "weight_tvm = tvm.nd.array(weight)\n",
        "conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
        "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
        "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
      ],
      "metadata": {
        "id": "P7JFDJ7KVa7g"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5.2.2. 练习 3：变换批量矩阵乘法程序¶"
      ],
      "metadata": {
        "id": "H0yz9yuMlaRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
        "    Y = np.empty((16, 128, 128), dtype=\"float32\")\n",
        "    for n in range(16):\n",
        "        for i in range(128):\n",
        "            for j in range(128):\n",
        "                for k in range(128):\n",
        "                    if k == 0:\n",
        "                        Y[n, i, j] = 0\n",
        "                    Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
        "    for n in range(16):\n",
        "        for i in range(128):\n",
        "            for j in range(128):\n",
        "                C[n, i, j] = max(Y[n, i, j], 0)"
      ],
      "metadata": {
        "id": "4BFN2wjglct7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyBmmRelu:\n",
        "  @T.prim_func\n",
        "  def bmm_relu(A: T.buffer((16, 128, 128), \"int64\"),\n",
        "               B: T.buffer((16, 128, 128), \"int64\"),\n",
        "               C: T.buffer((16, 128, 128), \"int64\")):\n",
        "    T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "    for n, i, j in T.grid(16, 128, 128):\n",
        "        with T.block(\"C\"):\n",
        "            vn = T.axis.spatial(16, n)\n",
        "            vi = T.axis.spatial(128, i)\n",
        "            vj = T.axis.spatial(128, j)\n",
        "            with T.init():\n",
        "                C[vn, vi, vj] = 0\n",
        "            for k in T.serial(0, 128):\n",
        "                with T.block(\"C_1\"):\n",
        "                    vk = T.axis.reduce(128, k)\n",
        "                    C[vn, vi, vj] = C[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
        "            with T.block(\"C_2\"):\n",
        "                C[vn, vi, vj] = T.max(C[vn, vi, vj], 0)\n",
        "\n",
        "sch = tvm.tir.Schedule(MyBmmRelu)\n",
        "IPython.display.Code(sch.mod.script(), language=\"python\")\n",
        "# Also please validate your result"
      ],
      "metadata": {
        "id": "GtqVFCWYloZG",
        "outputId": "eda6a300-8a9d-42bd-c4e6-c7ebaa42489b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "# from tvm.script import ir as I\n",
              "# from tvm.script import tir as T\n",
              "\n",
              "@I.ir_module\n",
              "class Module:\n",
              "    @T.prim_func\n",
              "    def bmm_relu(A: T.Buffer((16, 128, 128), \"int64\"), B: T.Buffer((16, 128, 128), \"int64\"), C: T.Buffer((16, 128, 128), \"int64\")):\n",
              "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
              "        # with T.block(\"root\"):\n",
              "        for n, i, j in T.grid(16, 128, 128):\n",
              "            with T.block(\"C\"):\n",
              "                vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
              "                T.reads(A[vn, vi, 0:128], B[vn, 0:128, vj])\n",
              "                T.writes(C[vn, vi, vj])\n",
              "                with T.init():\n",
              "                    C[vn, vi, vj] = T.int64(0)\n",
              "                for k in range(128):\n",
              "                    with T.block(\"C_1\"):\n",
              "                        vk = T.axis.reduce(128, k)\n",
              "                        T.reads(C[vn, vi, vj], A[vn, vi, vk], B[vn, vk, vj])\n",
              "                        T.writes(C[vn, vi, vj])\n",
              "                        C[vn, vi, vj] = C[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
              "                with T.block(\"C_2\"):\n",
              "                    T.reads(C[vn, vi, vj])\n",
              "                    T.writes(C[vn, vi, vj])\n",
              "                    C[vn, vi, vj] = T.max(C[vn, vi, vj], T.int64(0))"
            ],
            "text/html": [
              "<style>pre { line-height: 125%; }\n",
              "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
              "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
              "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
              "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
              ".output_html .hll { background-color: #ffffcc }\n",
              ".output_html { background: #f8f8f8; }\n",
              ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
              ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
              ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".output_html .o { color: #666666 } /* Operator */\n",
              ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
              ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
              ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
              ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
              ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
              ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
              ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
              ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
              ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
              ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
              ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
              ".output_html .go { color: #717171 } /* Generic.Output */\n",
              ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
              ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
              ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
              ".output_html .m { color: #666666 } /* Literal.Number */\n",
              ".output_html .s { color: #BA2121 } /* Literal.String */\n",
              ".output_html .na { color: #687822 } /* Name.Attribute */\n",
              ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
              ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".output_html .no { color: #880000 } /* Name.Constant */\n",
              ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
              ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
              ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
              ".output_html .nf { color: #0000FF } /* Name.Function */\n",
              ".output_html .nl { color: #767600 } /* Name.Label */\n",
              ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".output_html .nv { color: #19177C } /* Name.Variable */\n",
              ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
              ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
              ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
              ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
              ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
              ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
              ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
              ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
              ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
              ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
              ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
              ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># from tvm.script import ir as I</span>\n",
              "<span class=\"c1\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span class=\"nd\">@I</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
              "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
              "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">bmm_relu</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">),</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">),</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">)):</span>\n",
              "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">)})</span>\n",
              "        <span class=\"c1\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
              "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
              "                <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
              "                    <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">int64</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
              "                <span class=\"k\">for</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">):</span>\n",
              "                    <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C_1&quot;</span><span class=\"p\">):</span>\n",
              "                        <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">reduce</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">)</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
              "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C_2&quot;</span><span class=\"p\">):</span>\n",
              "                    <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">int64</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
              "</pre></div>\n"
            ],
            "text/latex": "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n\\PY{c+c1}{\\PYZsh{} from tvm.script import ir as I}\n\\PY{c+c1}{\\PYZsh{} from tvm.script import tir as T}\n\n\\PY{n+nd}{@I}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n    \\PY{k}{def} \\PY{n+nf}{bmm\\PYZus{}relu}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{bool}\\PY{p}{(}\\PY{k+kc}{True}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{}):}\n        \\PY{k}{for} \\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{l+m+mi}{0}\\PY{p}{:}\\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{l+m+mi}{0}\\PY{p}{:}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{int64}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n                \\PY{k}{for} \\PY{n}{k} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C\\PYZus{}1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                        \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{reduce}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{k}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C\\PYZus{}2}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{int64}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n\\end{Verbatim}\n"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sch = tvm.tir.Schedule(MyBmmRelu)\n",
        "# TODO: transformations\n",
        "# Hints: you can use\n",
        "# `IPython.display.Code(sch.mod.script(), language=\"python\")`\n",
        "# or `print(sch.mod.script())`\n",
        "# to show the current program at any time during the transformation.\n",
        "\n",
        "# Step 1. Get blocks\n",
        "Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
        "...\n",
        "\n",
        "# Step 2. Get loops\n",
        "b, i, j, k = sch.get_loops(Y)\n",
        "...\n",
        "\n",
        "# Step 3. Organize the loops\n",
        "k0, k1 = sch.split(k, ...)\n",
        "sch.reorder(...)\n",
        "sch.compute_at/reverse_compute_at(...)\n",
        "...\n",
        "\n",
        "# Step 4. decompose reduction\n",
        "Y_init = sch.decompose_reduction(Y, ...)\n",
        "...\n",
        "\n",
        "# Step 5. vectorize / parallel / unroll\n",
        "sch.vectorize(...)\n",
        "sch.parallel(...)\n",
        "sch.unroll(...)\n",
        "...\n",
        "\n",
        "IPython.display.Code(sch.mod.script(), language=\"python\")"
      ],
      "metadata": {
        "id": "VRTf_1vDpVLV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}